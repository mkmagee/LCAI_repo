{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6f796-d0eb-43b2-a567-bbea18c314a8",
   "metadata": {},
   "source": [
    "### To compare running the model on a CPU and GPU:\n",
    "\n",
    "- uses PyTorch's 'torch.device' to switch which device is being used\n",
    "- the CPU performs all computations for training (forward and backward passes) and inference\n",
    "\n",
    "## Plan:\n",
    "1. Model is defined by PyTorch's nn.Module\n",
    "2. Data is loaded using DataLoader\n",
    "3. Training: for epoch, model processes the training data by batch. For batch, data and target labels are moved to 'device', forward pass computes the output, loss is computed using 'CrossEntropyLoss', backward pass is performed to compute gradients, optimizer updates the model parameters\n",
    "4. Inference: model processes the test data by batch. For batch. data and target labels to moved to 'device', model performs forward pass to compute predictions. In addition, accuracy, inference time, throughput, CPU usage and memory usage are calculated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d18ae9-114d-49f4-b031-48d33961d311",
   "metadata": {},
   "source": [
    "# BEST Code to test both GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef3fcc-6e8a-4880-943a-6961cbf9466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.8614 - loss: 0.4786\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.9540 - loss: 0.1542\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.9670 - loss: 0.1107\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.9735 - loss: 0.0870\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.9768 - loss: 0.0724\n",
      "313/313 - 0s - 403us/step - accuracy: 0.9773 - loss: 0.0702\n",
      "CPU Training time: 6.73 seconds, Evaluation: [0.07018803060054779, 0.9772999882698059]\n",
      "Epoch 1/5\n",
      "\u001b[1m 376/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.8844"
     ]
    }
   ],
   "source": [
    "#load and prepare the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#function to train and evaluate the model on a specific device\n",
    "def run_experiment(device_name):\n",
    "    with tf.device(device_name):\n",
    "        # Rebuild the model for each device\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "        \n",
    "        #train the model\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train, epochs=5)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        #evaluate the model\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=2)\n",
    "        \n",
    "        return training_time, evaluation\n",
    "\n",
    "#run the experiment on CPU\n",
    "cpu_time, cpu_eval = run_experiment('/CPU:0')\n",
    "print(f\"CPU Training time: {cpu_time:.2f} seconds, Evaluation: {cpu_eval}\")\n",
    "\n",
    "#check if a GPU is available and run the experiment on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time, gpu_eval = run_experiment('/GPU:0')\n",
    "    print(f\"GPU Training time: {gpu_time:.2f} seconds, Evaluation: {gpu_eval}\")\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e614f-3d85-4c34-8e98-922d53f81cb0",
   "metadata": {},
   "source": [
    "# Testing CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e408fc2-2b97-4da0-a165-38a4cbbb391d",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8247b135-cce3-4be6-9b1d-d13064245567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1533-577e-4a6c-a384-459f69c486a2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ecefec-7c95-476c-b157-3279a5a483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transformations to prepare dataset for training neural network\n",
    "#ToTensor - converts PIL Image/ Numpy Arrays into PyTorch tensor\n",
    "#Normalize - normalizes tensor images with mean and sd\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#load datasets as train and test\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "#load in 64 samples at a time\n",
    "#shuffled at every epoch to prevent learning unintended patterns/ overfitting\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daf327-158a-4ce7-ae66-bb7118e44e3e",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a995c543-d081-467c-ba74-28a4af88f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    #initializes layers of the neural network\n",
    "    def __init__(self):\n",
    "        #constructor of parent class\n",
    "        super(SimpleNN, self).__init__()\n",
    "        #defines 3 linear (fully connected) layers\n",
    "        self.fc1 = nn.Linear(28 * 28, 128) #matches dimension size of input images, with 128 features in the layer\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 10) #10 matches number of classification classes\n",
    "\n",
    "    #defines forward pass of the neural network\n",
    "    def forward(self, x):\n",
    "        #flattens input tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #should return classification class, a digit 0-9\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521497d-bba1-40db-b588-c4a1eeb7052e",
   "metadata": {},
   "source": [
    "## System Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49516efd-ff07-4dfb-ad87-2c9df7bb2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get system metrics (cpu usage and memory)\n",
    "def get_system_metrics():\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    return cpu_usage, memory_info.percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca26de-c6e8-4ae4-9ccb-41dfca034d20",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0829945e-0ca1-4d33-b734-7effff61ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for training loop\n",
    "#set number of epoch to 5\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=5):\n",
    "    model.train() #sets model to training mode\n",
    "    total_training_time = 0  #initialize total training time\n",
    "    model.to(device)  # move model to the specified device\n",
    "    #loops over each 5 epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        #starts timer for time parameters\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0\n",
    "        #inner loop iterates over the batches of data from the training dataset\n",
    "        for batch_idx, (data, target) in enumerate(train_loader): \n",
    "            data, target = data.to(device), target.to(device)  # move data and target to the specified device\n",
    "            optimizer.zero_grad() #clears the gradients of optimized tensors\n",
    "            output = model(data) #passes training data through model\n",
    "            loss = criterion(output, target) #calculates loss (how well the model's predictions match the target values)\n",
    "            loss.backward()\n",
    "            optimizer.step() #updates model params\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_epoch_time = end_time - start_time #calculates total time taken for epoch\n",
    "        total_training_time += total_epoch_time  # Accumulate total training time\n",
    "\n",
    "        cpu_usage, memory_usage = get_system_metrics()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}, Time: {total_epoch_time:.2f}s, CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%')\n",
    "\n",
    "    #print total training time after all epochs\n",
    "    print(f'Total Training Time: {total_training_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418a112-d7bc-459b-b727-fd5716b3f6a0",
   "metadata": {},
   "source": [
    "## Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fff21d-051e-4fb7-98b3-704a977eef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference loop\n",
    "#create function for evaluation, with model and test data as parameters\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval() #sets model to evaluation mode\n",
    "    model.to(device)  # move model to the specified device\n",
    "    #initialize metircs\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_inference_time = 0\n",
    "\n",
    "    with torch.no_grad(): #disables gradient calculation (reduces memory usage and speeds up)\n",
    "        for batch_idx, (data, target) in enumerate(test_loader): #loops through batches from the test dataset\n",
    "            data, target = data.to(device), target.to(device)  # move data and target to the specified device\n",
    "            start_time = time.time()\n",
    "            output = model(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            inference_time = end_time - start_time #calculates inference time for current batch\n",
    "            total_inference_time += inference_time #adds up each inference time\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1) #finds the class w highest predicted score for each sample in the batch\n",
    "            total_correct += (predicted == target).sum().item() #compares predicted with actual label, counts the total num of correct predictions\n",
    "            total_samples += target.size(0) #gets the number of samples in the current batch and adds to count of total samples processed\n",
    "\n",
    "    accuracy = total_correct / total_samples \n",
    "    avg_inference_time = total_inference_time / len(test_loader)\n",
    "    throughput = total_samples / total_inference_time #computes the num of samples processed per second\n",
    "    \n",
    "    cpu_usage, memory_usage = get_system_metrics() #uses function from above\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}, Average Inference Time: {avg_inference_time:.4f}s, Throughput: {throughput:.2f} samples/s, CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4af88-4157-4d7f-8647-c33c5f716c9b",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcfb80d-58b5-4af5-8e5a-edd39fb0f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run the entire workflow on a specified device\n",
    "def run_experiment(device):\n",
    "    #initialize the model\n",
    "    model = SimpleNN()\n",
    "    #define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss() #CEL measures how well the model's predictions match the actual labels, best for classification\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01) #SGD updates the model params \n",
    "\n",
    "    #train the model by running training loop\n",
    "    train_model(model, train_loader, criterion, optimizer, device, num_epochs=5)\n",
    "    #evaluate the model using function \n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f92bfe-b77a-4fff-80f0-9ce2ab24468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Epoch [1/5], Loss: 1.0167, Time: 2.28s, CPU Usage: 15.6%, Memory Usage: 84.4%\n",
      "Epoch [2/5], Loss: 0.3849, Time: 2.12s, CPU Usage: 89.7%, Memory Usage: 84.3%\n",
      "Epoch [3/5], Loss: 0.3249, Time: 2.08s, CPU Usage: 84.4%, Memory Usage: 84.0%\n",
      "Epoch [4/5], Loss: 0.2922, Time: 2.09s, CPU Usage: 84.7%, Memory Usage: 84.3%\n",
      "Epoch [5/5], Loss: 0.2660, Time: 2.09s, CPU Usage: 86.8%, Memory Usage: 84.1%\n",
      "Total Training Time: 10.66s\n",
      "Accuracy: 0.9298, Average Inference Time: 0.0001s, Throughput: 1009022.32 samples/s, CPU Usage: 81.5%, Memory Usage: 84.3%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "\n",
    "#run the experiment on CPU\n",
    "run_experiment('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09eda6a2-43af-4083-aefb-a16aeb93d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run the experiment on GPU (if available)\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"Running on GPU:\")\n",
    "#     run_experiment('cuda')\n",
    "# else:\n",
    "#     print(\"CUDA is not available. Skipping GPU run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec32f1-c6b9-400f-b4ea-1c70587b0d26",
   "metadata": {},
   "source": [
    "# Testing GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e7d25f-24d9-4b12-bcee-a215db9cc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd04741-ac82-4fe1-9aa9-8a8c41396818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.18.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf5adb3-77c9-4b11-a4af-bc3fab9152e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-macos\n",
      "  Downloading tensorflow_macos-2.16.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
      "  Downloading tensorflow-2.16.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading grpcio-1.65.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.3.5)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.0)\n",
      "Downloading tensorflow_macos-2.16.2-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow-2.16.2-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.0/227.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.2-cp311-cp311-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl (283 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow, tensorflow-macos\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.2 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-macos-2.16.2 termcolor-2.4.0\n",
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.1.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-metal) (0.41.2)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-metal) (1.16.0)\n",
      "Downloading tensorflow_metal-1.1.0-cp311-cp311-macosx_12_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tensorflow-metal\n",
      "Successfully installed tensorflow-metal-1.1.0\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install tensorflow-macos\n",
    "# !python -m pip install tensorflow-metal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec5a346-6eaa-4b41-8872-6675e3bcb46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-08-02 10:36:53.548946: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-08-02 10:36:53.548998: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-08-02 10:36:53.549003: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-08-02 10:36:53.550452: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-08-02 10:36:53.553078: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 10:36:55.587642: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.4788\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9562 - loss: 0.1473\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.1069\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.0881\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0783\n",
      "Training time: 43.66 seconds\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9775 - loss: 0.0721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.072133369743824, 0.9775000214576721]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import time\n",
    "\n",
    "#load and prepare the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "#evaluate the model\n",
    "model.evaluate(x_test, y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4554f47-922c-433e-a8bb-2bafe96e8f29",
   "metadata": {},
   "source": [
    "# BEST Code to test both GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2e4987-b944-4aa6-9a56-e5a58cb31acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 590us/step - accuracy: 0.8573 - loss: 0.4895\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.9546 - loss: 0.1546\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - accuracy: 0.9676 - loss: 0.1034\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.9740 - loss: 0.0852\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.9769 - loss: 0.0742\n",
      "313/313 - 0s - 364us/step - accuracy: 0.9784 - loss: 0.0701\n",
      "CPU Training time: 6.28 seconds, Evaluation: [0.07007426768541336, 0.9783999919891357]\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.4843\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9570 - loss: 0.1443\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.1092\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0873\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0771\n",
      "313/313 - 1s - 3ms/step - accuracy: 0.9757 - loss: 0.0773\n",
      "GPU Training time: 43.04 seconds, Evaluation: [0.07732114940881729, 0.9757000207901001]\n"
     ]
    }
   ],
   "source": [
    "#load and prepare the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "#compile the model\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "#function to train and evaluate the model on a specific device\n",
    "def run_experiment(device_name):\n",
    "    with tf.device(device_name):\n",
    "        # Rebuild the model for each device\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "        \n",
    "        #train the model\n",
    "        start_time = time.time()\n",
    "        model.fit(x_train, y_train, epochs=5)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        #evaluate the model\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=2)\n",
    "        \n",
    "        return training_time, evaluation\n",
    "\n",
    "#run the experiment on CPU\n",
    "cpu_time, cpu_eval = run_experiment('/CPU:0')\n",
    "print(f\"CPU Training time: {cpu_time:.2f} seconds, Evaluation: {cpu_eval}\")\n",
    "\n",
    "#check if a GPU is available and run the experiment on GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time, gpu_eval = run_experiment('/GPU:0')\n",
    "    print(f\"GPU Training time: {gpu_time:.2f} seconds, Evaluation: {gpu_eval}\")\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
