{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6f796-d0eb-43b2-a567-bbea18c314a8",
   "metadata": {},
   "source": [
    "### To compare running the model on a CPU and GPU:\n",
    "\n",
    "- uses PyTorch's 'torch.device' to switch which device is being used\n",
    "- the CPU performs all computations for training (forward and backward passes) and inference\n",
    "\n",
    "## Plan:\n",
    "1. Model is defined by PyTorch's nn.Module\n",
    "2. Data is loaded using DataLoader\n",
    "3. Training: for epoch, model processes the training data by batch. For batch, data and target labels are moved to 'device', forward pass computes the output, loss is computed using 'CrossEntropyLoss', backward pass is performed to compute gradients, optimizer updates the model parameters\n",
    "4. Inference: model processes the test data by batch. For batch. data and target labels to moved to 'device', model performs forward pass to compute predictions. In addition, accuracy, inference time, throughput, CPU usage and memory usage are calculated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e408fc2-2b97-4da0-a165-38a4cbbb391d",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8247b135-cce3-4be6-9b1d-d13064245567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1533-577e-4a6c-a384-459f69c486a2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ecefec-7c95-476c-b157-3279a5a483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transformations to prepare dataset for training neural network\n",
    "#ToTensor - converts PIL Image/ Numpy Arrays into PyTorch tensor\n",
    "#Normalize - normalizes tensor images with mean and sd\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#load datasets as train and test\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "#load in 64 samples at a time\n",
    "#shuffled at every epoch to prevent learning unintended patterns/ overfitting\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daf327-158a-4ce7-ae66-bb7118e44e3e",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a995c543-d081-467c-ba74-28a4af88f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    #initializes layers of the neural network\n",
    "    def __init__(self):\n",
    "        #constructor of parent class\n",
    "        super(SimpleNN, self).__init__()\n",
    "        #defines 3 linear (fully connected) layers\n",
    "        self.fc1 = nn.Linear(28 * 28, 128) #matches dimension size of input images, with 128 features in the layer\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 10) #10 matches number of classification classes\n",
    "\n",
    "    #defines forward pass of the neural network\n",
    "    def forward(self, x):\n",
    "        #flattens input tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #should return classification class, a digit 0-9\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521497d-bba1-40db-b588-c4a1eeb7052e",
   "metadata": {},
   "source": [
    "## System Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49516efd-ff07-4dfb-ad87-2c9df7bb2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get system metrics (cpu usage and memory)\n",
    "def get_system_metrics():\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    return cpu_usage, memory_info.percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca26de-c6e8-4ae4-9ccb-41dfca034d20",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0829945e-0ca1-4d33-b734-7effff61ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for training loop\n",
    "#set number of epoch to 5\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=5):\n",
    "    model.train() #sets model to training mode\n",
    "    total_training_time = 0  #initialize total training time\n",
    "    model.to(device)  # move model to the specified device\n",
    "    #loops over each 5 epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        #starts timer for time parameters\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0\n",
    "        #inner loop iterates over the batches of data from the training dataset\n",
    "        for batch_idx, (data, target) in enumerate(train_loader): \n",
    "            data, target = data.to(device), target.to(device)  # move data and target to the specified device\n",
    "            optimizer.zero_grad() #clears the gradients of optimized tensors\n",
    "            output = model(data) #passes training data through model\n",
    "            loss = criterion(output, target) #calculates loss (how well the model's predictions match the target values)\n",
    "            loss.backward()\n",
    "            optimizer.step() #updates model params\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_epoch_time = end_time - start_time #calculates total time taken for epoch\n",
    "        total_training_time += total_epoch_time  # Accumulate total training time\n",
    "\n",
    "        cpu_usage, memory_usage = get_system_metrics()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}, Time: {total_epoch_time:.2f}s, CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%')\n",
    "\n",
    "    #print total training time after all epochs\n",
    "    print(f'Total Training Time: {total_training_time:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418a112-d7bc-459b-b727-fd5716b3f6a0",
   "metadata": {},
   "source": [
    "## Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fff21d-051e-4fb7-98b3-704a977eef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference loop\n",
    "#create function for evaluation, with model and test data as parameters\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval() #sets model to evaluation mode\n",
    "    model.to(device)  # move model to the specified device\n",
    "    #initialize metircs\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_inference_time = 0\n",
    "\n",
    "    with torch.no_grad(): #disables gradient calculation (reduces memory usage and speeds up)\n",
    "        for batch_idx, (data, target) in enumerate(test_loader): #loops through batches from the test dataset\n",
    "            data, target = data.to(device), target.to(device)  # move data and target to the specified device\n",
    "            start_time = time.time()\n",
    "            output = model(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            inference_time = end_time - start_time #calculates inference time for current batch\n",
    "            total_inference_time += inference_time #adds up each inference time\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1) #finds the class w highest predicted score for each sample in the batch\n",
    "            total_correct += (predicted == target).sum().item() #compares predicted with actual label, counts the total num of correct predictions\n",
    "            total_samples += target.size(0) #gets the number of samples in the current batch and adds to count of total samples processed\n",
    "\n",
    "    accuracy = total_correct / total_samples \n",
    "    avg_inference_time = total_inference_time / len(test_loader)\n",
    "    throughput = total_samples / total_inference_time #computes the num of samples processed per second\n",
    "    \n",
    "    cpu_usage, memory_usage = get_system_metrics() #uses function from above\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}, Average Inference Time: {avg_inference_time:.4f}s, Throughput: {throughput:.2f} samples/s, CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4af88-4157-4d7f-8647-c33c5f716c9b",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcfb80d-58b5-4af5-8e5a-edd39fb0f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run the entire workflow on a specified device\n",
    "def run_experiment(device):\n",
    "    #initialize the model\n",
    "    model = SimpleNN()\n",
    "    #define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss() #CEL measures how well the model's predictions match the actual labels, best for classification\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01) #SGD updates the model params \n",
    "\n",
    "    #train the model by running training loop\n",
    "    train_model(model, train_loader, criterion, optimizer, device, num_epochs=5)\n",
    "    #evaluate the model using function \n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f92bfe-b77a-4fff-80f0-9ce2ab24468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Epoch [1/5], Loss: 1.0596, Time: 20.16s, CPU Usage: 34.7%, Memory Usage: 85.4%\n",
      "Epoch [2/5], Loss: 0.3830, Time: 10.60s, CPU Usage: 72.5%, Memory Usage: 85.4%\n",
      "Epoch [3/5], Loss: 0.3207, Time: 12.83s, CPU Usage: 71.8%, Memory Usage: 84.6%\n",
      "Epoch [4/5], Loss: 0.2875, Time: 13.17s, CPU Usage: 74.6%, Memory Usage: 85.1%\n",
      "Epoch [5/5], Loss: 0.2615, Time: 15.98s, CPU Usage: 71.7%, Memory Usage: 85.4%\n",
      "Total Training Time: 72.73s\n",
      "Accuracy: 0.9303, Average Inference Time: 0.0008s, Throughput: 83244.27 samples/s, CPU Usage: 71.2%, Memory Usage: 85.1%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "\n",
    "#run the experiment on CPU\n",
    "run_experiment('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09eda6a2-43af-4083-aefb-a16aeb93d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run the experiment on GPU (if available)\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"Running on GPU:\")\n",
    "#     run_experiment('cuda')\n",
    "# else:\n",
    "#     print(\"CUDA is not available. Skipping GPU run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f630e-8361-4132-ba46-cc7ea46050e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
