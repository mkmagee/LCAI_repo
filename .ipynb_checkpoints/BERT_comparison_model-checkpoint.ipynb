{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523286c6-c5eb-446e-9a53-ddcc7a26a60d",
   "metadata": {},
   "source": [
    "### Comparing Training and Evaluation Performance of a Simple Neural Network on CPU and GPU using TensorFlow and PyTorch:\n",
    "\n",
    "- uses PyTorch's 'torch.device' to switch which device is being used\n",
    "- the CPU performs all computations for training (forward and backward passes) and inference\n",
    "\n",
    "## Plan:\n",
    "1. Model is defined by PyTorch's nn.Module\n",
    "2. Data is loaded using DataLoader\n",
    "3. Training: for epoch, model processes the training data by batch. For batch, data and target labels are moved to 'device', forward pass computes the output, loss is computed using 'CrossEntropyLoss', backward pass is performed to compute gradients, optimizer updates the model parameters\n",
    "4. Inference: model processes the test data by batch. For batch. data and target labels to moved to 'device', model performs forward pass to compute predictions. In addition, accuracy, inference time, throughput, CPU usage and memory usage are calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e88f5bee-1e13-4915-ab26-17c32940b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.65.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: tensorflow_datasets in /opt/anaconda3/lib/python3.11/site-packages (4.9.6)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (4.2.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (4.25.4)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (16.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Requirement already satisfied: simple-parsing in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (0.1.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (4.66.4)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: etils>=1.9.1 in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.9.2)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2023.10.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.2.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser~=0.15 in /opt/anaconda3/lib/python3.11/site-packages (from simple-parsing->tensorflow_datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.63.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow tensorflow_datasets\n",
    "#!pip install tf-keras\n",
    "# !pip install transformers\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de78c6bf-f0dd-4148-909c-58679690d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForQuestionAnswering\n",
    "#from tf_keras import BertTokenizer, TFBertForQuestionAnswering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "811cfda1-f0c0-4219-abd7-87809f021535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='squad',\n",
      "    full_name='squad/v1.1/3.0.0',\n",
      "    description=\"\"\"\n",
      "    Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset,\n",
      "    consisting of questions posed by crowdworkers on a set of Wikipedia articles,\n",
      "    where the answer to every question is a segment of text, or span, from the\n",
      "    corresponding reading passage, or the question might be unanswerable.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Version 1.1.0 of SQUAD\n",
      "    \"\"\",\n",
      "    homepage='https://rajpurkar.github.io/SQuAD-explorer/',\n",
      "    data_dir='/Users/mayamagee/tensorflow_datasets/squad/v1.1/3.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=33.51 MiB,\n",
      "    dataset_size=94.06 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'answers': Sequence({\n",
      "            'answer_start': int32,\n",
      "            'text': Text(shape=(), dtype=string),\n",
      "        }),\n",
      "        'context': Text(shape=(), dtype=string),\n",
      "        'id': string,\n",
      "        'question': Text(shape=(), dtype=string),\n",
      "        'title': Text(shape=(), dtype=string),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=87599, num_shards=1>,\n",
      "        'validation': <SplitInfo num_examples=10570, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{2016arXiv160605250R,\n",
      "           author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
      "                     Konstantin and {Liang}, Percy},\n",
      "            title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
      "          journal = {arXiv e-prints},\n",
      "             year = 2016,\n",
      "              eid = {arXiv:1606.05250},\n",
      "            pages = {arXiv:1606.05250},\n",
      "    archivePrefix = {arXiv},\n",
      "           eprint = {1606.05250},\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load the SQuAD dataset from TensorFlow Datasets\n",
    "dataset, info = tfds.load('squad', with_info=True)\n",
    "\n",
    "#print dataset info\n",
    "print(info)\n",
    "\n",
    "\n",
    "#split the dataset into training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "#load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#function to tokenize the input text\n",
    "def tokenize_function(question, context):\n",
    "    return tokenizer(\n",
    "        question.numpy().decode('utf-8'), \n",
    "        context.numpy().decode('utf-8'), \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        max_length=512\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb784745-531e-4fcd-a3fc-54c9f5ed777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tokenize the training and validation data\n",
    "def preprocess_function(example):\n",
    "    tokenized_example = tf.py_function(\n",
    "        func=tokenize_function,\n",
    "        inp=[example['question'], example['context']],\n",
    "        Tout=[tf.int32, tf.int32, tf.int32]\n",
    "    )\n",
    "    tokenized_example = {\n",
    "        'input_ids': tokenized_example[0],\n",
    "        'attention_mask': tokenized_example[1],\n",
    "        'token_type_ids': tokenized_example[2]\n",
    "    }\n",
    "    start_positions = example['answers']['answer_start'][0]\n",
    "    end_positions = start_positions + tf.strings.length(example['answers']['text'][0])\n",
    "    \n",
    "    return {\n",
    "        'input_ids': tokenized_example['input_ids'],\n",
    "        'attention_mask': tokenized_example['attention_mask'],\n",
    "        'token_type_ids': tokenized_example['token_type_ids'],\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f954a327-8911-49f3-9a03-2985f26eb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(preprocess_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.map(preprocess_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Prepare the data for training\n",
    "train_dataset = train_dataset.shuffle(1000).batch(8).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(8).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044f80c-595d-4bc0-afdb-f111bb0896b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd430b92-2aa1-487e-9b1e-6f07a26b2fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
